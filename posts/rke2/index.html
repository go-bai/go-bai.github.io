<!doctype html><html lang=en-us><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><title>使用 RKE2 快速搭建 k8s 集群 | gobai's blog</title>
<link rel=stylesheet href=/css/style.css><link rel=stylesheet href=/css/fonts.css><link href=//cdnjs.cloudflare.com/ajax/libs/highlight.js/11.7.0/styles/xcode.min.css rel=stylesheet><style>h2::before,h3::before,h4::before,h5::before{color:#8f8f8f}h2::before{content:"## "}h3::before{content:"### "}h4::before{content:"#### "}h5::before{content:"##### "}</style></head><body><nav><ul class=menu><li><a href=/>Home</a></li><li><a href=/about/>About</a></li><li><a href=/tags/>Tags</a></li><li><a href=/index.xml>Subscribe</a></li></ul><hr></nav><div class=article-meta><h1><span class=title>使用 RKE2 快速搭建 k8s 集群</span></h1><p class=date>2024/07/01</p><p class=terms>Tags: <a href=/tags/k8s>k8s</a> <a href=/tags/rke2>rke2</a></p></div><nav id=TableOfContents><ul><li><a href=#安装-rke2>安装 RKE2</a><ul><li><a href=#安装第一个-server-节点>安装第一个 server 节点</a><ul><li><a href=#配置介绍>配置介绍</a><ul><li><a href=#tls-san><code>tls-san</code></a></li><li><a href=#etcd-expose-metrics><code>etcd-expose-metrics</code></a></li></ul></li></ul></li><li><a href=#安装其他-server-节点>安装其他 server 节点</a></li><li><a href=#配置节点>配置节点</a></li></ul></li><li><a href=#rke2架构>RKE2架构</a><ul><li><a href=#进程生命周期>进程生命周期</a></li></ul></li><li><a href=#一些常用目录文件>一些常用目录/文件</a></li><li><a href=#连接-etcd>连接 etcd</a><ul><li><a href=#查看-etcd-集群状态>查看 etcd 集群状态</a></li></ul></li><li><a href=#参考>参考</a></li></ul></nav><main><p>根据<a href=../creating-a-bridged-network-with-netplan-on-ubuntu-22-04/>创建 bridge 网络</a>和<a href=../create-vm-with-cloudinit/>创建虚拟机时使用 cloudinit 初始化</a>创建虚拟机, 并配置静态ip如下</p><table><thead><tr><th>主机名</th><th>配置</th><th>ip (域名)</th><th>系统盘 / 数据盘</th></tr></thead><tbody><tr><td>k8s-node01</td><td>8核16G</td><td>192.168.1.218 (<code>lb.k8s.lan</code>)</td><td>50GB / 100GB*1</td></tr><tr><td>k8s-node02</td><td>8核16G</td><td>192.168.1.219</td><td>50GB / 100GB*1</td></tr><tr><td>k8s-node03</td><td>8核16G</td><td>192.168.1.220</td><td>50GB / 100GB*1</td></tr></tbody></table><h2 id=安装-rke2>安装 RKE2</h2><h3 id=安装第一个-server-节点>安装第一个 server 节点</h3><p>在 k8s-node01 节点执行</p><pre><code class=language-bash># 初始化 rke2 配置文件
mkdir -p /etc/rancher/rke2
cat &lt;&lt;EOF &gt; /etc/rancher/rke2/config.yaml
tls-san:
  - lb.k8s.lan
write-kubeconfig-mode: &quot;0600&quot;
disable-cloud-controller: true
# 为了节省资源使用的 flannel, 也可以使用 calico
cni: flannel
debug: true
# 指定 kube-scheduler 自定义参数, 会自动覆盖到 /var/lib/rancher/rke2/agent/pod-manifests/kube-scheduler.yaml
kube-scheduler-arg:
  - v=4
  - bind-address=0.0.0.0
kube-controller-manager-arg:
  - bind-address=0.0.0.0
etcd-expose-metrics: true
EOF

curl -sfL https://rancher-mirror.rancher.cn/rke2/install.sh | INSTALL_RKE2_MIRROR=cn sh -
systemctl enable rke2-server.service
systemctl start rke2-server.service
</code></pre><h4 id=配置介绍>配置介绍</h4><h5 id=tls-san><code>tls-san</code></h5><p><code>tls-san</code> 在 server 的 TLS 证书中增加了多个地址作为 <code>Subject Alternative Name</code>, 这样就可以通过 <code>lb.k8s.lan</code> 和 各个 server 节点 ip 访问 apiserver 服务.</p><h5 id=etcd-expose-metrics><code>etcd-expose-metrics</code></h5><p>默认为 <code>false</code>, <code>rke2</code> 会使用 <code>k3s</code> 代码 <code>pkg/etcd/etcd.go</code> 中的 <code>func (e *ETCD) cluster(ctx context.Context, reset bool, options executor.InitialOptions) error</code> 生成 <code>/var/lib/rancher/rke2/server/db/etcd/config</code> 文件存储 etcd 启动需要的参数, 其中就包含 <code>listen-metrics-urls: http://127.0.0.1:2381,http://192.168.1.218:2381</code>, 如果只监听了 <code>loopback</code> 地址, 那么 prometheus 抓不到对应的 metrics 数据, 如下是代码部分</p><pre><code class=language-golang>// cluster calls the executor to start etcd running with the provided configuration.
func (e *ETCD) cluster(ctx context.Context, reset bool, options executor.InitialOptions) error {
	ctx, e.cancel = context.WithCancel(ctx)
	return executor.ETCD(ctx, executor.ETCDConfig{
		Name:                e.name,
		InitialOptions:      options,
		ForceNewCluster:     reset,
		ListenClientURLs:    e.listenClientURLs(reset),
		ListenMetricsURLs:   e.listenMetricsURLs(reset), // 这里指定 metrics 监听的端口
		ListenPeerURLs:      e.listenPeerURLs(reset),
		AdvertiseClientURLs: e.advertiseClientURLs(reset),
		DataDir:             dbDir(e.config),
		ServerTrust: executor.ServerTrust{
			CertFile:       e.config.Runtime.ServerETCDCert,
			KeyFile:        e.config.Runtime.ServerETCDKey,
			ClientCertAuth: true,
			TrustedCAFile:  e.config.Runtime.ETCDServerCA,
		},
		PeerTrust: executor.PeerTrust{
			CertFile:       e.config.Runtime.PeerServerClientETCDCert,
			KeyFile:        e.config.Runtime.PeerServerClientETCDKey,
			ClientCertAuth: true,
			TrustedCAFile:  e.config.Runtime.ETCDPeerCA,
		},
		SnapshotCount:                   10000,
		ElectionTimeout:                 5000,
		HeartbeatInterval:               500,
		Logger:                          &quot;zap&quot;,
		LogOutputs:                      []string{&quot;stderr&quot;},
		ExperimentalInitialCorruptCheck: true,
		ListenClientHTTPURLs:            e.listenClientHTTPURLs(),
	}, e.config.ExtraEtcdArgs)
}

// listenMetricsURLs returns a list of URLs to bind to for metrics connections.
func (e *ETCD) listenMetricsURLs(reset bool) string {
	metricsURLs := fmt.Sprintf(&quot;http://%s:2381&quot;, e.config.Loopback(true))
	if !reset &amp;&amp; e.config.EtcdExposeMetrics { // 如果设置为 true 则增加监听主机 host 地址
		metricsURLs += &quot;,&quot; + fmt.Sprintf(&quot;http://%s&quot;, net.JoinHostPort(e.address, &quot;2381&quot;))
	}
	return metricsURLs
}
</code></pre><p>生成 etcd 配置文件之后, etcd 的 static pod manifest 中的启动命令就是 <code>etcd --config-file=/var/lib/rancher/rke2/server/db/etcd/config</code>, 配置文件通过 hostPath 方式挂载.</p><h3 id=安装其他-server-节点>安装其他 server 节点</h3><p>初始化 rke2 配置文件, 需要修改 <code>/etc/rancher/rke2/config.yaml</code> 中的 token</p><pre><code class=language-bash># 从第一个 server 节点的 /var/lib/rancher/rke2/server/node-token 获取
token=&lt;edit-me&gt;
mkdir -p /etc/rancher/rke2
cat &lt;&lt;EOF &gt; /etc/rancher/rke2/config.yaml
server: https://lb.k8s.lan:9345
token: $token
tls-san:
  - lb.k8s.lan
write-kubeconfig-mode: &quot;0600&quot;
disable-cloud-controller: true
cni: flannel
debug: true
# 指定 kube-scheduler 自定义参数, 会自动覆盖到 /var/lib/rancher/rke2/agent/pod-manifests/kube-scheduler.yaml
kube-scheduler-arg:
  - v=4
  - bind-address=0.0.0.0
etcd-expose-metrics: true
EOF
</code></pre><p>安装</p><pre><code class=language-bash>curl -sfL https://rancher-mirror.rancher.cn/rke2/install.sh | INSTALL_RKE2_MIRROR=cn sh -
systemctl enable rke2-server.service
systemctl start rke2-server.service
</code></pre><h3 id=配置节点>配置节点</h3><p>server 和 worker 节点都需要执行</p><pre><code class=language-bash># kubectl ctr crictl...
CONFIG=&quot;PATH=\$PATH:/var/lib/rancher/rke2/bin/&quot;
grep &quot;$CONFIG&quot; ~/.bashrc || echo &quot;$CONFIG&quot; &gt;&gt; ~/.bashrc &amp;&amp; source ~/.bashrc

# command auto completiom
CONFIG=&quot;source &lt;(kubectl completion bash)&quot;
grep &quot;$CONFIG&quot; ~/.bashrc || echo &quot;$CONFIG&quot; &gt;&gt; ~/.bashrc &amp;&amp; source ~/.bashrc

# KUBECONFIG ENV
CONFIG=&quot;export KUBECONFIG=/etc/rancher/rke2/rke2.yaml&quot;
grep &quot;$CONFIG&quot; ~/.bashrc || echo &quot;$CONFIG&quot; &gt;&gt; ~/.bashrc &amp;&amp; source ~/.bashrc

# CRI_CONFIG_FILE
CONFIG=&quot;export CRI_CONFIG_FILE=/var/lib/rancher/rke2/agent/etc/crictl.yaml&quot;
grep &quot;$CONFIG&quot; ~/.bashrc || echo &quot;$CONFIG&quot; &gt;&gt; ~/.bashrc &amp;&amp; source ~/.bashrc

# alias ctr=&quot;ctr --address /run/k3s/containerd/containerd.sock --namespace k8s.io&quot;
CONFIG=&quot;alias ctr=\&quot;ctr --address /run/k3s/containerd/containerd.sock --namespace k8s.io\&quot;&quot;
grep &quot;$CONFIG&quot; ~/.bashrc || echo &quot;$CONFIG&quot; &gt;&gt; ~/.bashrc &amp;&amp; source ~/.bashrc

# install helm
HELM_LATEST_VERSION=v3.15.2
wget https://get.helm.sh/helm-${HELM_LATEST_VERSION}-linux-amd64.tar.gz
tar -zxvf helm-${HELM_LATEST_VERSION}-linux-amd64.tar.gz
mv linux-amd64/helm /usr/local/bin/helm
rm -f helm-${HELM_LATEST_VERSION}-linux-amd64.tar.gz &amp;&amp; rm -rf linux-amd64/
</code></pre><p>worker 节点的 kubeconfig <code>/etc/rancher/rke2/rke2.yaml</code> 需要从 server 节点上拷贝, 无需修改</p><h2 id=rke2架构>RKE2架构</h2><p>RKE2 Server 和 Agent 有利用 k3s 的 agent</p><h3 id=进程生命周期>进程生命周期</h3><p>rke2进程使用systemd守护运行, rke2生成containerd进程和kubelet进程, 然后apiserver controller-manager scheduler etcd kube-proxy以static pod的形式被kubelet启动</p><p>containerd进程退出时rke2也会重启, kubelet进程退出时rke2会再拉起一个kubelet进程</p><pre><code class=language-bash># ps -e --forest
    899 ?        01:32:51 rke2
   1101 ?        01:58:12  \_ containerd
   1123 ?        05:23:44  \_ kubelet
   1227 ?        00:02:15 containerd-shim
   1344 ?        00:00:00  \_ pause
   1500 ?        05:12:21  \_ etcd
   1228 ?        00:02:22 containerd-shim
   1353 ?        00:00:00  \_ pause
   2516 ?        06:26:44  \_ kube-controller
   1229 ?        00:02:16 containerd-shim
   1342 ?        00:00:00  \_ pause
   2614 ?        00:44:00  \_ cloud-controlle
   1267 ?        00:02:18 containerd-shim
   1363 ?        00:00:00  \_ pause
   1452 ?        00:08:46  \_ kube-proxy
   1920 ?        00:00:00      \_ timeout &lt;defunct&gt;
   1283 ?        00:02:19 containerd-shim
   1341 ?        00:00:00  \_ pause
   1541 ?        00:51:47  \_ kube-scheduler
   1801 ?        00:20:15 containerd-shim
   1821 ?        00:00:00  \_ pause
   1852 ?        15:16:04  \_ kube-apiserver
</code></pre><h2 id=一些常用目录文件>一些常用目录/文件</h2><table><thead><tr><th>目录/文件</th><th>说明</th></tr></thead><tbody><tr><td><code>/var/lib/rancher/rke2/agent/pod-manifests</code></td><td>static pod 文件</td></tr><tr><td><code>/var/lib/rancher/rke2/agent/etc/containerd/config.toml</code></td><td>containerd配置文件</td></tr><tr><td><code>/var/lib/rancher/rke2/agent/containerd/containerd.log</code></td><td>containerd日志</td></tr><tr><td><code>/var/lib/rancher/rke2/agent/logs/kubelet.log</code></td><td>kubelet日志</td></tr><tr><td><code>/var/lib/rancher/rke2/server/db/etcd/config</code></td><td>etcd配置文件</td></tr><tr><td><code>/etc/rancher/rke2/config.yaml</code></td><td><a href=https://docs.rke2.io/install/configuration#configuration-file>rke2配置文件</a></td></tr></tbody></table><h2 id=连接-etcd>连接 etcd</h2><pre><code class=language-bash>ETCD_CONTAINER_ID=$(crictl ps --label=io.kubernetes.container.name=etcd --quiet)
ETCD_CA_CERT=/var/lib/rancher/rke2/server/tls/etcd/server-ca.crt
ETCD_CLIENT_CERT=/var/lib/rancher/rke2/server/tls/etcd/server-client.crt
ETCD_CLIENT_KEY=/var/lib/rancher/rke2/server/tls/etcd/server-client.key
</code></pre><h3 id=查看-etcd-集群状态>查看 etcd 集群状态</h3><pre><code class=language-bash>$ crictl exec -it $ETCD_CONTAINER_ID etcdctl --cacert $ETCD_CA_CERT --cert $ETCD_CLIENT_CERT --key $ETCD_CLIENT_KEY endpoint status --cluster --write-out=table
+----------------------------+------------------+---------+---------+-----------+------------+-----------+------------+--------------------+--------+
|          ENDPOINT          |        ID        | VERSION | DB SIZE | IS LEADER | IS LEARNER | RAFT TERM | RAFT INDEX | RAFT APPLIED INDEX | ERRORS |
+----------------------------+------------------+---------+---------+-----------+------------+-----------+------------+--------------------+--------+
| https://192.168.1.219:2379 | a6bc98228859ce05 |  3.5.13 |  5.5 MB |     false |      false |         3 |      14026 |              14026 |        |
| https://192.168.1.220:2379 | b3d0ba8f8abb8a75 |  3.5.13 |  5.4 MB |     false |      false |         3 |      14026 |              14026 |        |
| https://192.168.1.218:2379 | d61af8cc4ec4d5b1 |  3.5.13 |  8.5 MB |      true |      false |         3 |      14026 |              14026 |        |
+----------------------------+------------------+---------+---------+-----------+------------+-----------+------------+--------------------+--------+
</code></pre><h2 id=参考>参考</h2><ul><li><a href=https://docs.rke2.io/zh/install/quickstart>[RKE2 docs] quickstart</a></li><li><a href=https://docs.rke2.io/zh/reference/cli_tools>[RKE2 docs] CLI 工具</a></li></ul></main><footer><script defer src=https://cdn.jsdelivr.net/npm/@xiee/utils/js/center-img.js></script><script src=https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.7.0/highlight.min.js></script><script>hljs.configure({languages:[]}),hljs.highlightAll()</script><hr>© <a href=https://blog.gocn.top>gobai</a> 2021 &ndash; 2024 | <a href=https://github.com/go-bai>Github</a></footer></body></html>